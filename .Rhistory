# 1-1. 시행횟수가 6이고 성공확률이 1/3인 이항분포에서 성공횟수가 3이 될 확률
dbinom(3, 6, prob=1/3)
# 1-2. 평균이 170이고 표준편차가 6인 정규분포에서 상위20%되는 사람들의 키 범위
1-pnorm(0.2, 170, 6)
# 1-2. 평균이 170이고 표준편차가 6인 정규분포에서 상위20%되는 사람들의 키 범위
(1-pnorm(0.2, 170, 6))
# 1-2. 평균이 170이고 표준편차가 6인 정규분포에서 상위20%되는 사람들의 키 범위
1-pnorm(0.2, 170, 6)
# 1-1. 시행횟수가 6이고 성공확률이 1/3인 이항분포에서 성공횟수가 3이 될 확률
dbinom(3, 6, prob=1/3)
pnorm(0.2, 170, 6)
qchisq(0.05, df)
# 1-4. 자유도가 2인 t-분포에서 누적확률이 0.975일 때의 값
pt(0.975, 2)
# 1-3. 자유도가 3인 카이제곱분포에서 누적확률이 95%일 때의 값
qchisq(0.05, 3)
# 2.
cat("정답: 2,4,5번")
# 3.
head(iris)
library(dplyr)
iris_setosa<-iris %>%
filter(Species=='setosa')
iris_setosa
mean(iris_setosa)
mean(iris_setosa$Sepal.Length)
sd(iris_setosa$Sepal.Length)
cor(iris_setosa$Sepal.Length)
var(iris_setosa$Sepal.Length)
dim(iris_setosa$Sepal.Length)
str(iris_setosa$Sepal.Length)
# 1-4. 자유도가 2인 t-분포에서 누적확률이 0.975일 때의 값
qt(0.975, 2)
# 1-3. 자유도가 3인 카이제곱분포에서 누적확률이 95%일 때의 값
pchisq(0.05, 3)
# 1-3. 자유도가 3인 카이제곱분포에서 누적확률이 95%일 때의 값
pchisq(0.95, 3)
sd(iris_setosa$Sepal.Length)
var(iris_setosa$Sepal.Length)
avg<-mean(iris_setosa$Sepal.Length)
str(iris)
length(iris)
iris
avg-1.96*
x<-50
x<-50
y<-150
p.hat<-x/y
alpha<-0.05
z<-qnorm(1-(alpha/2)))
z<-qnorm(1-(alpha/2))
ll <- p.hat - z*sqrt(p.hat*(1-p.hat)/n)
ul <- p.hat + z*sqrt(p.hat*(1-p.hat)/n)
(c.i <- c(ll,ul))
(c.i <- c(ll,ul))
cat('약 0.304~0.363')
# 4. 한 농구 선수가 자유투를 던지면 10번중에서 7번 성공한다고 할 때 다음을 R을 이용하여 풀이하시오
# 4-1. 10번 던져서 9번 이상 성공할 확률
1-pbinom(9,size=10,prob=7/10)
# 4-2. 10번 던질 때 5번 이상 8번 이하로 성공할 확률
pbinom(8,size=10,prob=7/10)-pbinom(5,size=10,prob=7/10)
# 5. 다음을 R을 이용하여 검정하시오
# 2006년 조사에 의하면 한국인의 1인 1일 평균 알코올 섭취량이 8.1g이다.
# 2008년 무작위로 뽑은 알코올 섭취량은 다음과 같다.
alcol<-c(16.90, 13.21, 15.67, 9.87, 13.15, 9.98, 3.56, 14.50, 8.12, 6.97)
#평균 알코올 섭취량이 달라졌다고 할 수 있는가?
shapiro.test(alcol)
t.test(grade,mu=8.1,alternative="greater")
t.test(alcol,mu=8.1,alternative="greater")
t.test(alcol,mu=8.1,alternative="two.sided")
t.test(alcol,mu=8.1,alternative="two.sided")
iris$Sepal.Length
iris_setosa<-iris %>%
filter(Species=='setosa')
t.test(alcol,mu=8.1,alternative="two.sided") #
# 5. 다음을 R을 이용하여 검정하시오
# 2006년 조사에 의하면 한국인의 1인 1일 평균 알코올 섭취량이 8.1g이다.
# 2008년 무작위로 뽑은 알코올 섭취량은 다음과 같다.
alcol<-c(16.90, 13.21, 15.67, 9.87, 13.15, 9.98, 3.56, 14.50, 8.12, 6.97)
#평균 알코올 섭취량이 달라졌다고 할 수 있는가?
# H0==달라졌다 v.s H1== 달라지지 않았다
shapiro.test(alcol) #p-value가 0.8 이므로 정규분포에 따른다고 볼수있다.
t.test(alcol,mu=8.1,alternative="two.sided")
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
rangenorm(-1.96, 1.96, 0, 1)
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
library(rangenorm)
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
install.packages('rangenorm')
library(rangenorm)
rangenorm(-1.96, 1.96, 0, 1)
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
rangenorm(-1.96, 1.96, 0, 1)
# 7. mpg 데이터셋에서 다음을 검정해 보시오.
# 7-1.
mpg
# 7. mpg 데이터셋에서 다음을 검정해 보시오.
# 7-1.
library(ggplot2)
mpg
mpg$cty[mpg$class=="subcompact"]
shapiro.test(mpg$cty[mpg$class=="subcompact"])
qqnorm(mpg$cty[mpg$class=="subcompact"]) ; qqline(mpg$cty[mpg$class=="subcompact"])
qqnorm(mpg$cty[mpg$class=="subcompact"]) ; qqline(mpg$cty[mpg$class=="subcompact"])
#정규성을 나타내지 않는다.
mpg$cty[mpg$class=="midsize"]
shapiro.test(mpg$cty[mpg$class=="midsize"])
qqnorm(mpg$cty[mpg$class=="midsize"]) ; qqline(mpg$cty[mpg$class=="midsize"])
#이거 또한 정규성을 나타내지 않는다.
#만약 두집단 모두 정규성을 따른다고 가정하면
mpg1 <- mpg %>%
filter(class %in% c("subcompact","midsize"))
var.test(mpg1$cty~mpg1$class)
#p-value의 값이 굉장히 작으므로, 유의수준 0.05 하에서 두 집단의 분산은 다르다고 결론내린다
t.test(mpg1$cty~mpg1$class,var.equal=F)
#7-2.
mpg$cty[mpg$fl=="r"]
shapiro.test(mpg$cty[mpg$fl=="r"])
qqnorm(mpg$cty[mpg$fl=="r"]) ; qqline(mpg$cty[mpg$fl=="r"])
#7-2.
mpg$cty[mpg$fl=="r"]
shapiro.test(mpg$hwy[mpg$fl=="r"])
qqnorm(mpg$hwy[mpg$fl=="r"]) ; qqline(mpg$hwy[mpg$fl=="r"])
#7-2.
mpg$hwy[mpg$fl=="r"]
shapiro.test(mpg$hwy[mpg$fl=="r"])
qqnorm(mpg$hwy[mpg$fl=="r"]) ; qqline(mpg$hwy[mpg$fl=="r"])
mpg$hwy[mpg$fl=="p"]
shapiro.test(mpg$hwy[mpg$fl=="p"])
qqnorm(mpg$hwy[mpg$fl=="p"]) ; qqline(mpg$hwy[mpg$fl=="p"])
var.test(mpg2$hwy~mpg2$fl)
# 이 유의수준 0.05보다 작다. 따라서 두 집단 모두 정규분포를 따르지 않는다고 결론내린다. 이에 따라 다음과 같이
# 두가지의 경우로 나누어서 검정한다.
# 만약 두 집단의 가격이 모두 정규분포를 따른다고 가정한다면 2-sample T-test를 사용한다.
mpg2 <- mpg %>%
filter(fl %in% c("r","p"))
var.test(mpg2$hwy~mpg2$fl)
var.test(mpg2$hwy~mpg2$fl)
t.test(mpg2$hwy~mpg2$fl,var.equal=F)
#검정결과, p-value의 값이 약 0.043이므로, 유의수준 0.05 하에서 두 집단의 분산은 다르다고 결론내린다.
t.test(mpg2$hwy~mpg2$fl,var.equal=F)
install.packages("knitr")
install.packages("knitr")
# 8. 적합도를 검정하시오
x <- c(322, 109, 99, 29)
chisq.test(x, p=c(9, 3, 3, 1)/16)
chisq.test(x, p=c(9, 3, 3, 1)/16)
#p-value의 값이 굉장히 작으므로, 유의수준 0.05 하에서 두 집단의 분산은 다르다고 결론내린다
t.test(mpg1$cty~mpg1$class,var.equal=F)
# 9.'women'을 이용하여 다음을 구하시오
women
# 9.'women'을 이용하여 다음을 구하시오
fit<-im(weight~height, data=women)
# 9.'women'을 이용하여 다음을 구하시오
fit<-lm(weight~height, data=women)
summary(fit)
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
library(dprep)
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
install.packages('dprep')
# 6.정규분포에서 from <=X<=to 확률을 구하는 함수
# rangenorm(from, to, mean, sd)을 작성하고 rangenorm(-1.96, 1.96, 0, 1)의 값을 구하시오.
pnorm(1.96,mean=0,sd=1)-pnorm(-1.96,mean=0,sd=1)
lm(weight~height+I(height^2), women)
# 9.'women'을 이용하여 다음을 구하시오
plot(weight~height, women)
cor.test(women$weight, women$height)
# 9.'women'을 이용하여 다음을 구하시오
plot(weight~height, women)
fit<-lm(weight~height, data=women)
summary(fit)
cor.test(women$weight, women$height)
lm(weight~height+I(height^2), women)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
y<-150
p.hat<-x/y
alpha<-0.05
z<-qnorm(1-(alpha/2))
ll <- p.hat - z*sqrt(p.hat*(1-p.hat)/n)
ul <- p.hat + z*sqrt(p.hat*(1-p.hat)/n)
(c.i <- c(ll,ul))
cat('약 0.304~0.363')
library(dplyr)
x<-50
y<-150
p.hat<-x/y
alpha<-0.05
z<-qnorm(1-(alpha/2))
ll <- p.hat - z*sqrt(p.hat*(1-p.hat)/n)
ul <- p.hat + z*sqrt(p.hat*(1-p.hat)/n)
(c.i <- c(ll,ul))
cat('약 0.304~0.363')
# 4-1. 10번 던져서 9번 이상 성공할 확률
1-pbinom(9,size=10,prob=7/10)
# 4-2. 10번 던질 때 5번 이상 8번 이하로 성공할 확률
pbinom(8,size=10,prob=7/10)-pbinom(5,size=10,prob=7/10)
cat("정답: 2,4,5번")
# 1-1. 시행횟수가 6이고 성공확률이 1/3인 이항분포에서 성공횟수가 3이 될 확률
dbinom(3, 6, prob=1/3)
# 1-2. 평균이 170이고 표준편차가 6인 정규분포에서 상위20%되는 사람들의 키 범위
1-pnorm(0.2, 170, 6)
# 1-3. 자유도가 3인 카이제곱분포에서 누적확률이 95%일 때의 값
pchisq(0.95, 3)
# 1-4. 자유도가 2인 t-분포에서 누적확률이 0.975일 때의 값
qt(0.975, 2)
# 1-5. 표준정규분포에서 확률변수의 값이 1일 때의 누적확률
1
library(dplyr)
x<-50
y<-150
p.hat<-x/y
alpha<-0.05
z<-qnorm(1-(alpha/2))
ll <- p.hat - z*sqrt(p.hat*(1-p.hat)/x)
ul <- p.hat + z*sqrt(p.hat*(1-p.hat)/x)
(c.i <- c(ll,ul))
cat('약 0.304~0.363')
#Selenium
install.packages("RSelenium")
library(RSelenium)
library(rvest)
library(stringr)
library(dplyr)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
remDr<-remoteDriver(remoteServerAddr="localhost", port=4445L, browserName="chrome")
remDr$open()
remDr$navigate("https://nid.naver.com/nidlogin.login")# 여기서'$'은 객체
txt_id <- remDr$findElement(using="id", value="id")
txt_pw <- remDr$findElement(using="id", value="pw")
login_btn <- remDr$findElement(using="class", value="btn_global")
txt_id <- remDr$findElement(using="css selector", "#id")
txt_pw <- remDr$findElement(using="id", value="pw")
login_btn <- remDr$findElement(using="class", value="btn_global")
txt_id$setElementAttribute("value", "lookatme0_0") # 아이디 입력
txt_pw$setElementAttribute("value", "wnsgur8553") # *에 비밀번호 입력
login_btn$clickElement()
remDr$navigate("https://mail.naver.com/")
mail_texts <- remDr$findElement(using="id", value="list_for_view")
# (using = 'css selector', "subject")
mail_texts
mail_texts <- mail_texts$getElementText()
mail_texts
tmp <- str_split(mail_texts, '\n') %>% .[[1]]
tmp
sender <- c()
subject <- c()
time <- c()
for (i in 1:20) {
sender <- c(sender, tmp[4*i-3])
subject <- c(subject, tmp[4*i-2])
time <- c(time, tmp[4*i-1])
}
df_mail <- data.frame(sender=sender, subject=subject, time=time)
df_mail
remDr$close()
mail_texts
tmp
df_mail
remDr$close()
#SpiderMan Far from home
library(rvest)
library(stringr)
library(dplyr)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
main_url<-'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='
html<-read_html(main_url)
tmp<-html%>%
html_node('.score_total') %>%
html_text('em') %>%
trim()
str_locate(tmp, "총")
pages <- str_sub(tmp, 9, -2)
pages
pages<-gsub(',', '', pages)
end_page<-ceiling(as.numeric(pages)/10)
#데이터를 저장할 데이터프레임 초기화
dfs <- data.frame(score=c(), review=c(), writer=c(), time=c())
for(total_pages in 1:end_page){
if(i%%100==0)
print(i)
url <- paste0(main_url, total_pages)
html <- read_html(url)
html %>%
html_node('iframe.ifr') %>%
html_attr('src')->url2
ifr_url <- paste0(main_url, url2)
html2 <- read_html(ifr_url)
html2 %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li,'.star_score') %>%
html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> comments
idx <- str_locate(comments, "\r")
review <- c(review, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
writer <- c(writer, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
time <- c(time, str_sub(comments, 1, idx[1]-1))
}
total_review <- data.frame(score=score, review=review, writer=writer, time=time)
dfs <- rbind.data.frame(dfs, total_review)
}
write.csv(dfs, "SpiderMan_review.csv" , row.names = FALSE)
setwd("D:/Workspace/R-Project")
install.packages(c("KoNLP", "wordcloud"))
alert <- readLines("oracle_alert_testdb.log")
head(alert)
#예저 1-7. 특정 키워드만 골라내서 분석하기 – 정규식 활용하기
setwd('D:/Workspace/R-lecture/Part2/stage1_wordcloud/Ex07_Regex')
library(KoNLP)
library(wordcloud)
alert <- readLines("oracle_alert_testdb.log")
head(alert)
error_1 <- gsub(" ","_",alert)
head(unlist(error_1), 20)
error_2 <- unlist(error_1)
error_2
error_2<- Filter(function(x) {nchar(x) >= 5} ,error_2)
head(error_2, 10)
error_3 <- grep("^ORA-+",error_2,value=T)
head(unlist(error_3), 20)
write(unlist(error_3),"alert_testdb2.log")
rev <- read.table("alert_testdb2.log")
nrow(rev)
errorcount <- table(rev)  # 반복되는 에러별로 집계를 해서 errorcount 에 저장합니다.
head(sort(errorcount, decreasing=T),20)
library(RColorBrewer)
palete <- brewer.pal(9,"Set1")
wordcloud(names(errorcount),freq=errorcount,scale=c(5,0.5),rot.per=0.25,min.freq=3,
random.order=F,random.color=T,colors=palete)
legend(0.3,0.85 ,"Oracle Alert Log File 분석 결과",cex=0.8,fill=NA , border=NA ,
bg="white" ,  text.col="red",text.font=2,box.col="red")
setwd('D:/Workspace/R-Project')
total_reaview <- read.csv("SpiderMan_review.csv")
head(total_reaview)
source('D:/Workspace/R-lecture/Part2/stage1_wordcloud/Ex07_Regex/ex07_script.R', encoding = 'UTF-8')
library(RColorBrewer)
total_review <- read.csv("SpiderMan_review.csv")
head(total_review)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
total_review <- read.csv("SpiderMan_review.csv")
head(total_review)
only_review<-total_review[,2]
head(only_review)
head(only_review, 20)
#예저 1-7. 특정 키워드만 골라내서 분석하기 – 정규식 활용하기
setwd('D:/Workspace/R-lecture/Part2/stage1_wordcloud/Ex07_Regex')
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
alert <- readLines("oracle_alert_testdb.log")
head(alert)
error_1 <- gsub(" ","_",alert)
head(unlist(error_1), 20)
error_2 <- unlist(error_1)
error_2<- Filter(function(x) {nchar(x) >= 5} ,error_2)
error_2
head(error_2, 10)
error_3 <- grep("^ORA-+",error_2,value=T)
head(unlist(error_3), 20)
head(unlist(error_3), 20)
write(unlist(error_3),"alert_testdb2.log")
rev <- read.table("alert_testdb2.log")
rev
nrow(rev)
errorcount <- table(rev)  # 반복되는 에러별로 집계를 해서 errorcount 에 저장합니다.
table(rev)
errorcount
head(only_review, 20)
only_review<-total_review[,2]
only_review
#SpiderMan Far from home
library(rvest)
library(stringr)
library(dplyr)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
main_url<-'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='
html<-read_html(main_url)
tmp<-html%>%
html_node('.score_total') %>%
html_text('em') %>%
trim()
str_locate(tmp, "총")
pages <- str_sub(tmp, 9, -2)
pages<-gsub(',', '', pages)
end_page<-ceiling(as.numeric(pages)/10)
end_page
#데이터를 저장할 데이터프레임 초기화
dfs <- data.frame(score=c(), review=c(), writer=c(), time=c())
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
main_url<-'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='
html<-read_html(main_url)
tmp<-html%>%
html_node('.score_total') %>%
html_text('em') %>%
trim()
str_locate(tmp, "총")
pages <- str_sub(tmp, 9, -2)
pages<-gsub(',', '', pages)
end_page<-ceiling(as.numeric(pages)/10)
#데이터를 저장할 데이터프레임 초기화
dfs <- data.frame(score=c(), review=c(), writer=c(), time=c())
for(total_pages in 1:end_page){
if(i %% 100 == 0)
print(i)
url <- paste0(main_url, total_pages)
html <- read_html(url) %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
# html %>%
#   html_node('iframe.ifr') %>%
#   html_attr('src')->url2
#
# ifr_url <- paste0(main_url, url2)
# html2 <- read_html(ifr_url)
# html2 %>%
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li,'.star_score') %>%
html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> comments
idx <- str_locate(comments, "\r")
review <- c(review, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
writer <- c(writer, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
time <- c(time, str_sub(comments, 1, idx[1]-1))
}
total_review <- data.frame(score=score, review=review, writer=writer, time=time)
dfs <- rbind.data.frame(dfs, total_review)
}
for(total_pages in 1:end_page){
if(total_pages %% 100 == 0)
print(total_pages)
url <- paste0(main_url, total_pages)
html <- read_html(url) %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
# html %>%
#   html_node('iframe.ifr') %>%
#   html_attr('src')->url2
#
# ifr_url <- paste0(main_url, url2)
# html2 <- read_html(ifr_url)
# html2 %>%
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li,'.star_score') %>%
html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> comments
idx <- str_locate(comments, "\r")
review <- c(review, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
writer <- c(writer, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
time <- c(time, str_sub(comments, 1, idx[1]-1))
}
total_review <- data.frame(score=score, review=review, writer=writer, time=time)
dfs <- rbind.data.frame(dfs, total_review)
}
write.csv(dfs, "SpiderMan_review.csv" , row.names = FALSE)
#WordCloud from SpiderMan reviews
setwd('D:/Workspace/R-Project')
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
total_review <- read.csv("SpiderMan_review.csv")
only_review<-total_review[,2]
only_review
useSejongDic() #한글 세종사전
Nouns <- sapply(only_review, extractNoun, USE.NAMES=F) #각 라인마다 명사단어들만 남기기
head(Nouns)
tail(Nouns)
View(Nouns)
Nouns_List <- unlist(Nouns) #단어들만 가져오기
Nouns_List
