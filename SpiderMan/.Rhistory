family="font")
wordcount <- table(Nouns2)
wordcount
Nouns <- sapply(only_review, extractNoun, USE.NAMES=F) #각 라인마다 명사단어들만 남기기
Nouns #리스트형태의 명사만 추출된 데이터
Nouns2<-unlist(Nouns); #명사만 추출된 데이터
Nouns2<-Filter(function(x) {nchar(x)>=2}, Nouns2) #2글자 이상만
head(Nouns2, 50)
Nouns2<-Filter(function(x) {nchar(x)>=2}, Nouns2) #2글자 이상만
head(Nouns2, 50)
#WordCloud from SpiderMan reviews
setwd('D:/Workspace/R-Project')
library(rJava)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
useSejongDic() #한글 세종사전
only_review<-readLines('SpiderMan_only_review.txt')
Nouns <- sapply(only_review, extractNoun, USE.NAMES=F) #각 라인마다 명사단어들만 남기기
Nouns #리스트형태의 명사만 추출된 데이터
Nouns2<-unlist(Nouns); #명사만 추출된 데이터
Nouns2<-Filter(function(x) {nchar(x)>=2}, Nouns2) #2글자 이상만
head(Nouns2, 50)
wordcount <- table(Nouns2)
wordcount
head(wordcount)
wordcount_top <-head(sort(wordcount, decreasing = T),100)
wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=3, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(11, "Paired"), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(8, "Paired"), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
wordcount_top<-gsub('영화','',wordcount_top)
wordcount_top<-gsub('진짜짜','',wordcount_top)
wordcount_top<-gsub('진짜','',wordcount_top)
wordcount_top<-gsub('영화','',wordcount_top)
wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(8, "Paired"), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
#WordCloud from SpiderMan reviews
setwd('D:/Workspace/R-Project')
library(rJava)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
useSejongDic() #한글 세종사전
only_review<-readLines('SpiderMan_only_review.txt')
Nouns <- sapply(only_review, extractNoun, USE.NAMES=F) #각 라인마다 명사단어들만 남기기
Nouns2<-unlist(Nouns); #명사만 추출된 데이터
Nouns2<-Filter(function(x) {nchar(x)>=2}, Nouns2) #2글자 이상만
head(Nouns2, 50)
Nouns2<-gsub('영화','',Nouns2)
Nouns2<-gsub('진짜','',Nouns2)
wordcount <- table(Nouns2)
head(wordcount)
wordcount_top <-head(sort(wordcount, decreasing = T),100)
wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(8, "Paired"), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
wordcount_top <-head(sort(wordcount, decreasing = T),200)
wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(8, "Paired"), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.2), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(5,0.4), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.7), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
set.seed(1234)
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC
# 최종 이미지파일로 저장
savePlot(SM_WC, type="png”)
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
())
()
}
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
# 최종 이미지파일로 저장
savePlot(SM_WC, type='PNG')
print()
# 최종 이미지파일로 저장
savePlot(SM_WC, type='png')
# 최종 이미지파일로 저장
savePlot(SM_WC, type='png')
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
# 최종 이미지파일로 저장
savePlot(SM_WC, type='png')
SM_WC
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
#WordCloud from SpiderMan reviews
setwd('D:/Workspace/R-Project')
library(rJava)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
useSejongDic() #한글 세종사전
only_review<-readLines('SpiderMan_only_review.txt')
Nouns <- sapply(only_review, extractNoun, USE.NAMES=F) #각 라인마다 명사단어들만 남기기
Nouns2<-unlist(Nouns); #명사만 추출된 데이터
Nouns2<-Filter(function(x) {nchar(x)>=2}, Nouns2) #2글자 이상만
head(Nouns2, 50)
Nouns2<-gsub('영화','',Nouns2)
Nouns2<-gsub('진짜','',Nouns2)
Nouns2 <- gsub('[ㄱ-ㅎ]','',Nouns2)
Nouns2<- gsub('(ㅜ|ㅠ)','',Nouns2)
Nouns2 <- gsub("\\d+","",Nouns2)
Nouns2
Nouns2 <- gsub("\\","",Nouns2)
wordcount <- table(Nouns2)
head(wordcount)
Nouns2<- gsub('[~!@#$%&*()_+=?<>]','',Nouns2)
wordcount <- table(Nouns2)
head(wordcount)
wordcount_top <-head(sort(wordcount, decreasing = T),200)
set.seed(1234)
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(7,0.6), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
SM_WC<-wordcloud(
names(wordcount_top),
freq=wordcount_top,
scale=c(8,0.5), #빈도가 가장 큰 단어와 가장 빈도가 작은단어 폰사 사이 크기
rot.per=0.1, #90도 회전해서 보여줄 단어 비율
min.freq=2, # 빈도 3이상
random.order=F, # True : 랜덤배치, False : 빈도수가 큰단어를 중앙에 배치
random.color=T, # True : 색랜덤, False : 빈도순
colors=brewer.pal(10,'Dark2'), #11은 사용할 색상개수, 두번째는 색상타입이름
family="font")
#WordCloud from SpiderMan reviews
install.packages('wordcloud2')
library(wordcloud2)
wordcloud2(wordcount_top, size=0.5, col="random-light", backgroundColor="black")
wordcloud2(wordcount_top, size=1, col="random-light", backgroundColor="black")
wordcloud2(wordcount_top, size=1.5, col="random-light", backgroundColor="black")
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
set.seed(123)
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
Nouns2<- gsub('[~!@#$%&*()"_+=?<>]','',Nouns2)
wordcount <- table(Nouns2)
head(wordcount)
wordcount_top <-head(sort(wordcount, decreasing = T),200)
set.seed(123)
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
Nouns2<-gsub('스파이더맨은','',Nouns2)
Nouns2<-gsub('스파이더맨을','',Nouns2)
Nouns2<-gsub('스파이더맨이','',Nouns2)
wordcount <- table(Nouns2)
wordcount_top <-head(sort(wordcount, decreasing = T),200)
set.seed(123)
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
wordcount <- table(Nouns2)
wordcount_top <-head(sort(wordcount, decreasing = T),300)
set.seed(123)
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
Nouns2<-gsub('스파이더맨','',Nouns2)
wordcount <- table(Nouns2)
wordcount_top <-head(sort(wordcount, decreasing = T),300)
set.seed(123)
wordcloud2(wordcount_top, size=2, col="random-light", backgroundColor="black")
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="black")
Nouns2<- gsub('[~!@#$%&*^^()"_+=?<>]','',Nouns2)
wordcount <- table(Nouns2)
wordcount_top <-head(sort(wordcount, decreasing = T),300)
set.seed(123)
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="black")
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="lightred")
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="red")
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="pink")
wordcloud2(wordcount_top, size=3, col="random-light", backgroundColor="black")
#SpiderMan Far from home
library(rvest)
library(stringr)
library(dplyr)
trim <- function(x) gsub("^\\s+|\\s+$", "", x)
main_url<-'https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=173123&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page='
html<-read_html(main_url)
tmp<-html%>%
html_node('.score_total') %>%
html_text('em') %>%
trim()
str_locate(tmp, "총")
pages <- str_sub(tmp, 9, -2)
pages<-gsub(',', '', pages)
end_page<-ceiling(as.numeric(pages)/10)
#데이터를 저장할 데이터프레임 초기화
dfs <- data.frame(score=c(), review=c(), writer=c(), time=c())
for(total_pages in 1:end_page){
if(total_pages %% 100 == 0)
print(total_pages)
url <- paste0(main_url, total_pages)
html <- read_html(url) %>%
html_node('div.score_result') %>%
html_nodes('li') -> lis
# html %>%
#   html_node('iframe.ifr') %>%
#   html_attr('src')->url2
#
# ifr_url <- paste0(main_url, url2)
# html2 <- read_html(ifr_url)
# html2 %>%
score <- c()
review <- c()
writer <- c()
time <- c()
for (li in lis) {
score <- c(score, html_node(li,'.star_score') %>%
html_text('em') %>% trim())
li %>%
html_node('.score_reple') %>%
html_text('p') %>%
trim() -> comments
idx <- str_locate(comments, "\r")
review <- c(review, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
writer <- c(writer, str_sub(comments, 1, idx[1]-1))
comments <- trim(str_sub(comments, idx[1], -1))
idx <- str_locate(comments, "\r")
time <- c(time, str_sub(comments, 1, idx[1]-1))
}
total_review <- data.frame(score=score, review=review, writer=writer, time=time)
dfs <- rbind.data.frame(dfs, total_review)
}
write.csv(dfs, "SpiderMan_review.csv" , row.names = FALSE)
setwd("D:/Workspace/R-Project/SpiderMan")
#일자별/시간대별 평점 분석을 할 것
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
data
data<-data[,-2]
data
tail(data)
head(data)
#일자별/시간대별 평점 분석을 할 것
library(ggplot2)
ggplot(data,aes(x=time, y=score))+
geom_point(color='blue')
ggplot(data,aes(x=time, y=score))+
geom_histogram(color='blue')
ggplot(data,aes(x=time, y=score))+
geom_bar(color='blue')
ggplot(data,aes(x=time, y=score))+
ggplot(data,aes(x=time, y=score))+
geom_bar(aes(color='blue'))
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
data
data<-data[,-2&&-3]
data2<-data[,-2&&-3]
data2
data2<-data[,-2&-3]
data2
data2<-data[,-2]
data2
data3<-data2[,-2]
data3
ggplot(data3,aes(x=time, y=score))+
geom_bar(aes(color='blue'))
ggplot(data3,aes(x=time))+
geom_histogram(aes(color='blue'))
ggplot(data3,aes(x=time))+
geom_histogram(aes(color='blue'),stat='bin')
ggplot(data3,aes(x=time))+
geom_histogram(aes(y=score),stat='bin')
library(dplyr)
mean(data3$score)
data3%>%
filter(score %in% c('2019.07.02'))
data3
date02<-data3 %>%
filter(score %in% c('2019.07.02'))
head(date02)
date02<-data3 %>%
filter(score =='2019.07.02')
date02
date02<-data %>%
filter(score =='2019.07.02')
date02
head(data)
data
data2<-data[,-2]
data3<-data2[,-2]
data3
date02<-data %>%
filter(score =='2019.07.02')
date02
filter(data3, score =='2019.07.02')
data3
#filter(data3, score =='2019.07.02')
arrange(data3, time)
#filter(data3, score =='2019.07.02')
arrange(data3, desc(time))
data2<-select(data, score, time)
data3
data2
filter(data2, score =='2019.07.02')
filter(data2, score =='2019.07.02+')
filter(data2, score =='^2019.07.02')
filter(data2, score ==^2019.07.02)
select(data2, contains(2019.07.02))
select(data2, contains('2019.07.02'))
select(data2, contains('2019.07.02'))
arrange(data3, desc(time))
select(data2, matches('2019.07.02'))
hist(data2)
hist_plot(data2)
cbind(data2, perday=substr(data2$time,1, 10))
cbind(data2, perday=substr(data2$time,6, 10))
cbind(data, time2=substr(data$time,12, 17))
cbind(data, time2=substr(data$time,12, 17))
cbind(data, perday=substr(data$time,6, 10))
data2<-cbind(data, perday=substr(data$time,6, 10))
data3<-cbind(data2, time2=substr(data2$time,12, 17))
data4<-select(data3, score, perday, time2)
data4
select(data4, matches('2019.07.02'))
data4 %>%
filter(perday %in% ('2019.07.02'))
data4 %>%
filter(perday %in% c('2019.07.02'))
data4
data4 %>%
filter(perday %in% c('07.02'))
data4 %>%
filter(perday %in% c('07.02')) %>%
summarise(average=mean(score))
install.packages("gridExtra")
data4
hist(data4)
hist(data4$perday)
hist(data4$score)
data4<-gsub('.','',data4$perday)
data4
data4<-gsub('.',' ',data4$perday)
data4<-gsub('.','',data4$perday)
data4<-gsub('.','', data4[,2])
data<-as.numeric(data$time)
head(data)
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
data2<-cbind(data, perday=substr(data$time,6, 10))
data3<-cbind(data2, time2=substr(data2$time,12, 17))
data3
#data4<-select(data3, score, perday, time2)
data3<-gsub('.','', data3$perday)
head(data3)
#data4<-select(data3, score, perday, time2)
data3<-gsub('.','', data3)
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
data2<-cbind(data, perday=substr(data$time,6, 10))
data3<-cbind(data2, time2=substr(data2$time,12, 17))
data3
#data4<-select(data3, score, perday, time2)
data3<-gsub('.','', data3)
data3
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
data2<-cbind(data, perday=substr(data$time,6, 10))
data3<-cbind(data2, time2=substr(data2$time,12, 17))
data3
data4<-select(data3, score, perday, time2)
data4
hist(data4)
hist(data4$perday)
hist(data4$time2)
class(data4$perday)
as.numeric(data4$perday)
data4 %>%
group_by(perday)%>%
summarise(average=mean(score))
as.numeric(time2)
as.numeric(data4$time2)
data4
str(data4)
data
str(data)
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
str(data)
eachday<-data4 %>%
group_by(perday)%>%
summarise(average=mean(score))
hist(eachday)
setwd('D:/Workspace/R-Project/SpiderMan')
data<-read.csv('SpiderMan_review.csv')
str(data)
